---
title: "RBF SVM"
author: 'Lan Wen (UNI: lw2773)'
output: pdf_document
---

Step 0: Install packages and split dataset by sampling:

```{r,warning=FALSE,message=FALSE}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}

if(!require("e1071")){
  install.packages("e1071")
}

if(!require("ggplot2")){
  install.packages("ggplot2")
}

library("EBImage")
library("e1071")
library("ggplot2")
```

Split current features into train and test sets by sampling
```{r}
# Testset row numbers
set.seed(2018)
s1 <- sample(seq(1,1000,by=1), 100, replace = FALSE)
s2 <- sample(seq(1001,2000,by=1), 100, replace = FALSE)
s3 <- sample(seq(2001,3000,by=1), 100, replace = FALSE)
samp <- c(s1, s2, s3)
```


Step 1: Set up controls for evaluation experiments
```{r}
run.cv = TRUE
K = 5
#Specify method (Only implement one method at a time)
SIFT = FALSE
GIST = FALSE
HOG = FALSE
LBP = TRUE
```


Step 2: import features and training images class labels

Import features generated by feature extraction process.
```{r}
# need to update according to different feature sets
# SIFT
if (SIFT){
  raw.feature <- read.csv("../data/SIFT_train.csv", header = F)
  features <- as.matrix(raw.feature[,2:ncol(raw.feature)])
  rownames(features) <- raw.feature[,1]
  colnames(features) <- c(1:2000)
}

# GIST
if (GIST){
  raw.feature <- read.csv("../output/gist/gist10.csv", header = T)
  features <- as.matrix(raw.feature)
}

# HOG
if (HOG){
  load("../output/HOG.RData")
  features <- dat
}

# LBP
if (LBP){
  raw.feature <- read.csv("../output/lbp/lbp.csv",header = F)
  features <- as.matrix(raw.feature)
}

train_x <- features[-samp,]
test_x <- features[samp,]
```

```{r}
raw.labels <- read.csv("../data/label_train.csv", header = T)
labels <- as.factor(raw.labels[,3])

train_y <- labels[-samp]
test_y <- labels[samp]
```


Step 3: Train a classification model with training images

Model selection with cross-validation:
```{r}
if (run.cv){
  params <-list(cost=c(1,3,5,7,8),gamma=c(5,10,20,50))

  ## Tune the model:
  tc <- tune.control(cross = K)
  
  if (LBP == FALSE & HOG == FALSE){
    pca <- prcomp(train_x, scale = FALSE)
    pca_x <- pca$x[,1:100]
    svm_tune <- tune(svm, train.x = pca_x, train.y = train_y,
                   kernel = "radial", scale = F, ranges = params,
                   tunecontrol = tc)
  }else{
    svm_tune <- tune(svm, train.x = train_x, train.y = train_y,
                   kernel = "radial", scale = F, ranges = params,
                   tunecontrol = tc)
  }
  
  ## Performance of the model:
  perf_svm <- svm_tune$performances
}
```

Visualize cross-validation results:
```{r}
if (run.cv){
  ## Plot cost/gamma vs CV error:
  perf_svm$cost.f <- as.factor(perf_svm$cost)
  
  if (SIFT){
    error_plot <- ggplot(data = perf_svm)+ 
      geom_line(aes(x = gamma, y = error, linetype = cost.f, col = cost.f))+
      labs(title = "SIFT & RBF SVM", x = "Gamma", y = "Error Rate")
    print(error_plot)
  }
  
  else if (GIST){
    error_plot <- ggplot(data = perf_svm)+ 
      geom_line(aes(x = gamma, y = error, linetype = cost.f, col = cost.f))+
      labs(title = "GIST & RBF SVM", x = "Gamma", y = "Error Rate")
    print(error_plot)
  }
  
  else if (LBP){
    error_plot <- ggplot(data = perf_svm)+ 
      geom_line(aes(x = gamma, y = error, linetype = cost.f, col = cost.f))+
      labs(title = "LBP & RBF SVM", x = "Gamma", y = "Error Rate")
    print(error_plot)
  }
  
  else if (HOG){
    error_plot <- ggplot(data = perf_svm)+ 
      geom_line(aes(x = gamma, y = error, linetype = cost.f, col = cost.f))+
      labs(title = "HOG & RBF SVM", x = "Gamma", y = "Error Rate")
    print(error_plot)
  }
}
```

Choose the best parameters and train the model:
```{r}
tm_train <- NA
if (run.cv){
  ## CV Best parameters:
  best_cost <- perf_svm$cost[which.min(perf_svm$error)]
  best_gamma <- perf_svm$gamma[which.min(perf_svm$error)]

  ## Train the model with best parameters:
  t <- proc.time()
  fit_train <- svm(train_x, train_y, scale=F, kernel="radial", gamma = best_gamma, cost = best_cost)
  time_train <- (proc.time()-t)[3]
  } else{
  ## Train the model with default parameters:
  t <- proc.time()
  fit_train <- svm(train_x, train_y, scale=F, kernel="radial", gamma = 7, cost = 50)
  time_train <- (proc.time()-t)[3]
  }

## RBF SVM runtime
time_train

## Save the model:
if (SIFT){save(fit_train, file="../output/svm_model_sift.RData")}
if (GIST){save(fit_train, file="../output/svm_model_gist.RData")}
if (HOG){save(fit_train, file="../output/svm_model_hog.RData")}
if (LBP){save(fit_train, file="../output/svm_model_lbp.RData")}
```


Step 4: Model Evaluation:
Get the training and testing error based on the given data:
```{r}
## The training accuracy:
pred_train <- predict(fit_train, train_x)
accuracy_train <- mean(pred_train == train_y)

## The test accuracy:
pred_test <- predict(fit_train, test_x)
accuracy_test <- mean(pred_test == test_y)

## Save the result:
result <- c(time_train, accuracy_train, accuracy_test)
names(result) <- c("Processing time", "Training Accuracy", "Test Accuracy")

if (SIFT){save(result, file="../output/svm_result_sift.RData")}
if (GIST){save(result, file="../output/svm_result_gist.RData")}
if (HOG){save(result, file="../output/svm_result_hog.RData")}
if (LBP){save(result, file="../output/svm_result_lbp.RData")}
```