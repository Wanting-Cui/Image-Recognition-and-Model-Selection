"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab1, params = param , nround = 50, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- cv$evaluation_log[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
cv$evaluation_log[, 4]
a <- cv$evaluation_log[,4]
a <- c(cv$evaluation_log[,4])
a
mat[1, ] <- a
a <- data.matrix(cv$evaluation_log)[,4]
mat[1, ] <- a
mat[1,]
mat
mat <- matrix(NA, nrow = num, ncol = 50)
mat[1, ] <- a
View(mat)
list_max.depth <- c(5,10)
list_eta <- c(0.03, 0.3)
num <- length(list_max.depth) * length(list_eta)
vec <- rep("NA", num)
mat <- matrix(NA, nrow = num, ncol = 50)
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_eta)){
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab1, params = param , nround = 50, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- data.matrix(cv$evaluation_log)[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
View(xgb_grid_1)
error <- data.frame(cbind(vec, mat))
View(error)
library(reshape2)
error_melt <- melt(error, id.vars = vec)
colnames(error)[1] <- "cases"
error_melt <- melt(error, id.vars = 'cases')
View(error_melt)
View(error_melt)
ggplot(error_melt, mapping = aes(x = c(1:50), y = 'value'))+
geom_line(aes(color = 'cases'))
ggplot(error_melt, mapping = aes(x = c(1:50), y = 'value'))+
geom_line(aes(color = factor(cases)))
ggplot(error_melt, mapping = aes(x = c(1:50), y = 'value'))+
geom_line(aes(color = cases))
ggplot(error_melt, mapping = aes(x = c(1:50), y = 'value'))+
geom_line(aes(color = cases, group = cases))
ggplot(error_melt)+
geom_line(aes(mapping = aes(x = c(1:50), y = value, color = cases)))
ggplot(error_melt)+
geom_line(aes(x = c(1:50), y = value, color = cases))
ggplot(error_melt)+
geom_line(aes(x = c(1:200), y = value, color = cases))
ggplot(error_melt, aes(group = cases))+
geom_line(aes(x = c(1:50), y = value, color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_line(aes(x = c(1:200), y = value, color = cases))
colnames(e)
colnames(error) <- c("cases", 1:50)
error_melt <- melt(error, id.vars = 'cases')
ggplot(error_melt, mapping = aes(group = cases))+
geom_line(aes(x = variable, y = value, color = cases))
nrou <- 30
list_max.depth <- c(5,10)
list_eta <- c(0.03, 0.3)
num <- length(list_max.depth) * length(list_eta)
vec <- rep("NA", num)
mat <- matrix(NA, nrow = num, ncol = nrou)
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_eta)){
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab1, params = param , nround = nrou, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- data.matrix(cv$evaluation_log)[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
error <- data.frame(cbind(vec, mat))
colnames(error) <- c("cases", 1:nrou)
library(reshape2)
error_melt <- melt(error, id.vars = 'cases')
ggplot(error_melt, mapping = aes(group = cases))+
geom_line(aes(x = variable, y = value, color = cases))
ind <- read.table("../data/TEST-NUMBER.txt")
View(ind)
ind <- c(read.table("../data/TEST-NUMBER.txt"))
ind <- read.table("../data/TEST-NUMBER.txt")
ind <- data.matrix(read.table("../data/TEST-NUMBER.txt"))
ind <- data.matrix(read.table("../data/TEST-NUMBER.txt"), nrow = 1)
ind <- c(data.matrix(read.table("../data/TEST-NUMBER.txt")))
length(unique(ind))
setwd("~/GitHub/Spring2018-Project3-Group1/lib")
dat <- read.csv("../lib/gist/gist10.csv")
lab <- read.csv("../data/label_train.csv")
ind <- c(data.matrix(read.table("../data/TEST-NUMBER.txt")))
train <- dat[-ind, ]
lab_tr <- lab[-ind]
lab_tr <- lab[-ind, ]
train <- data.matrix(dat[-ind, ])
lab_tr <- data.matrix(lab[-ind, 3])
lab_tr[which(lab_tr == 3)] = 0
nrou <- 20
list_max.depth <- c(3, 5)
list_eta <- c(0.03, 0.3)
# list_max.depth <- c(3, 5,10, 20)
# list_eta <- c(0.03, 0.3, 0.8)
num <- length(list_max.depth) * length(list_eta)
vec <- rep("NA", num)
mat <- matrix(NA, nrow = num, ncol = nrou)
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_eta)){
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab_tr, params = param , nround = nrou, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- data.matrix(cv$evaluation_log)[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
error <- data.frame(cbind(vec, mat))
colnames(error) <- c("cases", 1:nrou)
library(reshape2)
error_melt <- melt(error, id.vars = 'cases')
ggplot(error_melt, mapping = aes(group = cases))+
geom_line(aes(x = variable, y = value, color = cases))
nrou <- 100
# list_max.depth <- c(3, 5)
# list_eta <- c(0.03, 0.3)
list_max.depth <- c(3, 5,10, 20)
list_eta <- c(0.03, 0.3, 0.8)
num <- length(list_max.depth) * length(list_eta)
vec <- rep("NA", num)
mat <- matrix(NA, nrow = num, ncol = nrou)
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_eta)){
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab_tr, params = param , nround = nrou, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- data.matrix(cv$evaluation_log)[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
error <- data.frame(cbind(vec, mat))
colnames(error) <- c("cases", 1:nrou)
library(reshape2)
error_melt <- melt(error, id.vars = 'cases')
ggplot(error_melt, mapping = aes(group = cases))+
geom_line(aes(x = variable, y = value, color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_curve(aes(x = variable, y = value, color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = value, color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(value, 4), color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(value, digits =4), color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(error_melt$value, digits =4), color = cases))
t <- round(error_melt$value, 4)
t <- round(error_melt$value[1], 4)
?round
class(error_melt$value)
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 6), color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))+
labs(title = "XGBOOST & GIST", xlab = "nround", ylab = "error rate")
?labs
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))+
labs(title = "XGBOOST & GIST", xlab("nround"), ylab("error rate"))
?labs
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))+
labs(title = "XGBOOST & GIST", x = "nround", ylab = "error rate")
ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))+
labs(title = "XGBOOST & GIST", x = "nround", y = "Error Rate")
?xgboost.cv
xgboost_cv <- function(nrou, list_max.depth, list_eta){
num <- length(list_max.depth) * length(list_eta)
vec <- rep("NA", num)
mat <- matrix(NA, nrow = num, ncol = nrou)
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_eta)){
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab_tr, params = param , nround = nrou, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- data.matrix(cv$evaluation_log)[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
error <- data.frame(cbind(vec, mat))
colnames(error) <- c("cases", 1:nrou)
library(reshape2)
error_melt <- melt(error, id.vars = 'cases')
plot1 <- ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))+
labs(title = "XGBOOST & GIST", x = "nround", y = "Error Rate")
return(list(error, plot1))
}
xgboost_cv <- function(train, lab, nrou, list_max.depth, list_eta){
num <- length(list_max.depth) * length(list_eta)
vec <- rep("NA", num)
mat <- matrix(NA, nrow = num, ncol = nrou)
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_eta)){
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab, params = param , nround = nrou, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- data.matrix(cv$evaluation_log)[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
error <- data.frame(cbind(vec, mat))
colnames(error) <- c("cases", 1:nrou)
library(reshape2)
error_melt <- melt(error, id.vars = 'cases')
plot1 <- ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))+
labs(title = "XGBOOST & GIST", x = "nround", y = "Error Rate")
return(list(error, plot1))
}
t <- xgboost(train = train, lab = lab_tr, nrou = 20, list_max.depth = c(3, 5), list_eta = c(0.3, 0.8))
train1 <- data.matrix(dat[-ind, ])
t <- xgboost(train = train1, lab = lab_tr, nrou = 20, list_max.depth = c(3, 5), list_eta = c(0.3, 0.8))
xgboost_cv <- function(train, lab, nrou, list_max.depth, list_eta){
num <- length(list_max.depth) * length(list_eta)
vec <- rep("NA", num)
mat <- matrix(NA, nrow = num, ncol = nrou)
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_eta)){
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab, params = param , nround = nrou, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- data.matrix(cv$evaluation_log)[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
error <- data.frame(cbind(vec, mat))
colnames(error) <- c("cases", 1:nrou)
library(reshape2)
error_melt <- melt(error, id.vars = 'cases')
plot1 <- ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))+
labs(title = "XGBOOST & GIST", x = "nround", y = "Error Rate")
return(list(error, plot1))
}
t <- xgboost(train = train1, lab = lab_tr, nrou = 20, list_max.depth = c(3, 5), list_eta = c(0.3, 0.8))
t <- xgboost_cv(train = train1, lab = lab_tr, nrou = 20, list_max.depth = c(3, 5), list_eta = c(0.3, 0.8))
t[[2]]
t1 <- t[[1]]
View(t1)
xgboost_cv <- function(train, lab, nrou, list_max.depth, list_eta, name){
num <- length(list_max.depth) * length(list_eta)
vec <- rep("NA", num)
mat <- matrix(NA, nrow = num, ncol = nrou)
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_eta)){
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab, params = param , nround = nrou, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- data.matrix(cv$evaluation_log)[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
error <- data.frame(cbind(vec, mat))
colnames(error) <- c("cases", 1:nrou)
library(reshape2)
error_melt <- melt(error, id.vars = 'cases')
plot1 <- ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))+
labs(title = paste0("XGBOOST & ", name), x = "nround", y = "Error Rate")
return(list(error, plot1))
}
t <- xgboost_cv(train = train1, lab = lab_tr, nrou = 20, list_max.depth = c(3, 5), list_eta = c(0.3, 0.8), name = "GIST")
t[[2]]
dat2 <- read.csv("../data/SIFT_train.csv")
dat2 <- read.csv("../data/SIFT_train.csv", header = FALSE)
train2 <- dat2[-ind, ]
sift_tr <- xgboost_cv(train = train1, lab = lab_tr, nrou = 100,
list_max.depth = c(3, 5, 10, 20), list_eta = c(0.03, 0.3, 0.8), name = "GIST")
sift_tr <- xgboost_cv(train = train2, lab = lab_tr, nrou = 100,
list_max.depth = c(3, 5, 10, 20), list_eta = c(0.03, 0.3, 0.8), name = "SIFT")
train2 <- data.matrix(dat2[-ind, ])
sift_tr <- xgboost_cv(train = train2, lab = lab_tr, nrou = 100,
list_max.depth = c(3, 5, 10, 20), list_eta = c(0.03, 0.3, 0.8), name = "SIFT")
sift_tr[[2]]
dat3 <- load("../output/HOG.RData")
load("../output/HOG.RData")
ind <- c(data.matrix(read.table("../data/TEST-NUMBER.txt")))
lab <- read.csv("../data/label_train.csv")
lab_tr <- data.matrix(lab[-ind, 3])
lab_tr[which(lab_tr == 3)] = 0
load("../output/HOG.RData")
View(dat)
dim(dat)
dat3 <- dat
xgboost_cv <- function(train, lab, nrou, list_max.depth, list_eta, name){
num <- length(list_max.depth) * length(list_eta)
vec <- rep("NA", num)
mat <- matrix(NA, nrow = num, ncol = nrou)
for(j in 1:length(list_max.depth)){
for(k in 1:length(list_eta)){
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = list_eta[k], "max.depth" = list_max.depth[j])
cv <- xgb.cv(data = train, label = lab, params = param , nround = nrou, nfold = 5, metrics = "merror", verbose = 0)
pos <- (j-1)*length(list_eta)+k
vec[pos] <- paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k])
mat[pos, ] <- data.matrix(cv$evaluation_log)[, 4]
# plot1 <- ggplot(cv$evaluation_log)+
#   geom_line(aes(x = iter, y = test_merror_mean))+
#   labs(title = paste0("max.depth = ", list_max.depth[j], ", eta = ", list_eta[k]))
# print(plot1)
}
}
error <- data.frame(cbind(vec, mat))
colnames(error) <- c("cases", 1:nrou)
library(reshape2)
error_melt <- melt(error, id.vars = 'cases')
plot1 <- ggplot(error_melt, mapping = aes(group = cases))+
geom_smooth(aes(x = variable, y = round(as.numeric(value), 4), color = cases))+
labs(title = paste0("XGBOOST & ", name), x = "nround", y = "Error Rate")
return(list(error, plot1))
}
train3 <- data.matrix(dat2[-ind, ])
train3 <- data.matrix(dat3[-ind, ])
hog_tr <- xgboost_cv(train = train3, lab = lab_tr, nrou = 100,
list_max.depth = c(3, 5, 10, 20), list_eta = c(0.03, 0.3, 0.8), name = "HOG")
hog_tr[[2]]
hog_tr[[2]]
hog_tr[[2]]
dat4 <- read.csv("../lib/lbp/lbp.csv")
dat4 <- read.csv("../lib/lbp/lbp.csv", header = FALSE)
train4 <- data.matrix(dat4[-ind, ])
lbp_tr <- xgboost_cv(train = train4, lab = lab_tr, nrou = 100,
list_max.depth = c(3, 5, 10, 20), list_eta = c(0.03, 0.3, 0.8), name = "LBP")
lbp_tr[[2]]
?xgboost
lab_tr[which(lab_tr == 3)] = 0
lab_te[which(lab_te == 3)] = 0
lab_te <- data.matrix(lab[ind, 3])
lab_te[which(lab_te == 3)] = 0
dat2 <- read.csv("../data/SIFT_train.csv", header = FALSE)
dat2 <- read.csv("../data/SIFT_train.csv", header = FALSE)
train2 <- data.matrix(dat2[-ind, ])
bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0)
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = 0.8, "max.depth" = 3)
bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0)
test <- dat2[ind, ]
pred <- predict(bst, test)
test <- data.matrix(dat2[ind, ])
pred <- predict(bst, test)
length(pred != lab_te)/300
length(pred != lab_te)
sum(pred != lab_te)/300
sum(pred != lab_te)
system.time()
?system.time
lab_te <- data.matrix(lab[ind, 3])
lab_te[which(lab_te == 3)] = 0
test <- data.matrix(dat2[ind, ])
system.time(
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = 0.8, "max.depth" = 3)
bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0)
lab_te <- data.matrix(lab[ind, 3])
lab_te[which(lab_te == 3)] = 0
test <- data.matrix(dat2[ind, ])
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = 0.8, "max.depth" = 3)
bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0)
pred <- predict(bst, test)
sum(pred != lab_te)/300
system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
sum(pred != lab_te)/300
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = 0.3, "max.depth" = 3)
system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
pred <- predict(bst, test)
sum(pred != lab_te)/300
param <- list("objective" = "multi:softmax",
"num_class" = 3,
"eta" = 0.8, "max.depth" = 3)
library("EBImage")
lab <- read.csv("../data/label_train.csv")
lab_tr <- data.matrix(lab[-ind, 3])
ind <- c(data.matrix(read.table("../data/TEST-NUMBER.txt")))
lab_tr <- data.matrix(lab[-ind, 3])
lab_te <- data.matrix(lab[ind, 3])
test <- data.matrix(dat2[ind, ])
dat2 <- read.csv("../data/SIFT_train.csv", header = FALSE)
train2 <- data.matrix(dat2[-ind, ])
test <- data.matrix(dat2[ind, ])
param <- list("objective" = "multi:softmax",
"num_class" = 4,
"eta" = 0.8, "max.depth" = 3)
system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
library(xgboost)
system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
pred <- predict(bst, test)
sum(pred != lab_te)/300
sum(pred != lab_te)
param <- list("objective" = "multi:softmax",
"num_class" = 5,
"eta" = 0.8, "max.depth" = 3)
system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
pred <- predict(bst, test)
sum(pred != lab_te)/300
sum(pred != lab_te)
pred
param <- list("objective" = "multi:softmax",
"num_class" = 6,
"eta" = 0.8, "max.depth" = 3)
system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
pred <- predict(bst, test)
sum(pred != lab_te)/300
sum(pred != lab_te)
param <- list("objective" = "multi:softmax",
"num_class" = 5,
"eta" = 0.8, "max.depth" = 3)
system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
pred <- predict(bst, test)
sum(pred != lab_te)/300
param <- list("objective" = "multi:softmax",
"num_class" = 5,
"eta" = 0.8, "max.depth" = 3)
system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
pred <- predict(bst, test)
sum(pred != lab_te)/300
param <- list("objective" = "multi:softmax",
"num_class" = 4,
"eta" = 0.8, "max.depth" = 3)
system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
pred <- predict(bst, test)
sum(pred != lab_te)/300
source("../lib/xgboost_cv.R")
View(xgboost_cv)
mat <- matrix(NA, nrow = num, ncol = nrou)
t1 <- system.time(bst <- xgboost(data = train2, label = lab_tr, params = param, nrounds = 40, verbose = 0))
t1
t1[1]
t1[3]
cat("Time for training model=", t1[3], "s \n")
cat("Time for training model is", t1[3], "s \n")
